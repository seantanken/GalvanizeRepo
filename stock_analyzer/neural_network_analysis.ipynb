{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "addressed-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy.random as rand\n",
    "import scipy.stats as stats \n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor \n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marked-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta, time, datetime\n",
    "import time\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-fireplace",
   "metadata": {},
   "source": [
    "Use root mean squared log error\n",
    "\n",
    "Pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-stick",
   "metadata": {},
   "source": [
    "train = 3 or 4 weeks, test = 1 day / week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-portfolio",
   "metadata": {},
   "source": [
    "## Train/Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-serbia",
   "metadata": {},
   "source": [
    "Creating train/test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-spokesman",
   "metadata": {},
   "source": [
    "train_test_split(y, shuffle=False) instead of manually selecting train/test data?\n",
    "\n",
    "or df2 = datasX.iloc[:, :72]\n",
    "   df2 = datasX.iloc[:, 72:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-being",
   "metadata": {},
   "source": [
    "Train = weeks 5/10/21 to 5/31/21\n",
    "\n",
    "Test = week 6/7/21 + 6/14/21 day "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-michael",
   "metadata": {},
   "source": [
    "# converting days to max and min for neural network prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "popular-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_start_lst = ['2021-05-10', '2021-05-17', '2021-05-24', '2021-05-31', '2021-06-7']\n",
    "week_start_df = pd.DataFrame(columns=['year', 'month', 'day'])\n",
    "for i, week in enumerate(week_start_lst):\n",
    "    split_week = week.split('-')\n",
    "    week_start_df.loc[i] = split_week[0], split_week[1], split_week[2]\n",
    "week_start_datetime = pd.to_datetime(week_start_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "transparent-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date       Open       High        Low      Close   Volume\n",
      "0  2021-05-10 09-30  3273.1101  3273.1101  3273.1101  3273.1101  98924.0\n",
      "1  2021-05-10 09-31  3269.8450  3269.8450  3269.8450  3269.8450  21831.0\n",
      "2  2021-05-10 09-32  3259.7500  3259.7500  3259.7500  3259.7500  30404.0\n",
      "3  2021-05-10 09-33  3259.0000  3259.0000  3259.0000  3259.0000  45721.0\n",
      "4  2021-05-10 09-34  3258.0000  3258.0000  3258.0000  3258.0000  32843.0\n",
      "               Date       Open       High        Low      Close    Volume\n",
      "0  2021-05-11 09-30  3145.9099  3145.9099  3145.9099  3145.9099  278087.0\n",
      "1  2021-05-11 09-31  3148.0601  3148.0601  3148.0601  3148.0601   55566.0\n",
      "2  2021-05-11 09-32  3152.2649  3152.2649  3152.2649  3152.2649   49978.0\n",
      "3  2021-05-11 09-33  3144.8523  3144.8523  3144.8523  3144.8523   34608.0\n",
      "4  2021-05-11 09-34  3144.6799  3144.6799  3144.6799  3144.6799   30181.0\n",
      "               Date       Open       High        Low      Close    Volume\n",
      "0  2021-05-17 09-30  3254.7451  3254.7451  3254.7451  3254.7451  133556.0\n",
      "1  2021-05-17 09-31  3249.9900  3249.9900  3249.9900  3249.9900   28646.0\n",
      "2  2021-05-17 09-32  3250.3040  3250.3040  3250.3040  3250.3040   16958.0\n",
      "3  2021-05-17 09-33  3241.0100  3241.0100  3241.0100  3241.0100   32738.0\n",
      "4  2021-05-17 09-34  3263.1201  3263.1201  3263.1201  3263.1201   47922.0\n",
      "               Date       Open       High        Low      Close    Volume\n",
      "0  2021-05-18 09-30  3288.6899  3288.6899  3288.6899  3288.6899  117407.0\n",
      "1  2021-05-18 09-31  3290.1699  3290.1699  3290.1699  3290.1699   14533.0\n",
      "2  2021-05-18 09-32  3285.0061  3285.0061  3285.0061  3285.0061   13799.0\n",
      "3  2021-05-18 09-33  3280.4900  3280.4900  3280.4900  3280.4900   15450.0\n",
      "4  2021-05-18 09-34  3282.8601  3282.8601  3282.8601  3282.8601    8586.0\n",
      "               Date       Open       High        Low      Close   Volume\n",
      "0  2021-05-24 09-30  3216.8899  3216.8899  3216.8899  3216.8899  84805.0\n",
      "1  2021-05-24 09-31  3211.8250  3211.8250  3211.8250  3211.8250  18442.0\n",
      "2  2021-05-24 09-32  3221.4600  3221.4600  3221.4600  3221.4600  15999.0\n",
      "3  2021-05-24 09-33  3221.6389  3221.6389  3221.6389  3221.6389  20387.0\n",
      "4  2021-05-24 09-34  3222.8601  3222.8601  3222.8601  3222.8601   8642.0\n",
      "               Date       Open       High        Low      Close   Volume\n",
      "0  2021-05-25 09-30  3271.4299  3271.4299  3271.4299  3271.4299  99545.0\n",
      "1  2021-05-25 09-31  3274.0000  3274.0000  3274.0000  3274.0000  27814.0\n",
      "2  2021-05-25 09-32  3277.6599  3277.6599  3277.6599  3277.6599  18531.0\n",
      "3  2021-05-25 09-33  3279.3999  3279.3999  3279.3999  3279.3999  13319.0\n",
      "4  2021-05-25 09-34  3272.5000  3272.5000  3272.5000  3272.5000  19831.0\n",
      "               Date       Open       High        Low      Close   Volume\n",
      "0  2021-05-28 09-30  3238.8601  3238.8601  3238.8601  3238.8601  57354.0\n",
      "1  2021-05-28 09-31  3240.3701  3240.3701  3240.3701  3240.3701  18579.0\n",
      "2  2021-05-28 09-32  3237.2800  3237.2800  3237.2800  3237.2800   6122.0\n",
      "3  2021-05-28 09-33  3238.9998  3238.9998  3238.9998  3238.9998   9945.0\n",
      "4  2021-05-28 09-34  3235.7400  3235.7400  3235.7400  3235.7400  10742.0\n",
      "               Date       Open       High        Low      Close   Volume\n",
      "0  2021-06-01 09-30  3242.1299  3242.1299  3242.1299  3242.1299  92419.0\n",
      "1  2021-06-01 09-31  3242.4299  3242.4299  3242.4299  3242.4299  11825.0\n",
      "2  2021-06-01 09-32  3243.8000  3243.8000  3243.8000  3243.8000  14076.0\n",
      "3  2021-06-01 09-33  3240.5701  3240.5701  3240.5701  3240.5701  16328.0\n",
      "4  2021-06-01 09-34  3240.0000  3240.0000  3240.0000  3240.0000   7346.0\n",
      "               Date       Open       High        Low      Close   Volume\n",
      "0  2021-06-07 09-30  3200.0000  3200.0000  3200.0000  3200.0000  66583.0\n",
      "1  2021-06-07 09-31  3197.0000  3197.0000  3197.0000  3197.0000  17104.0\n",
      "2  2021-06-07 09-32  3198.0977  3198.0977  3198.0977  3198.0977  16985.0\n",
      "3  2021-06-07 09-33  3198.8899  3198.8899  3198.8899  3198.8899  16474.0\n",
      "4  2021-06-07 09-34  3199.5801  3199.5801  3199.5801  3199.5801  10516.0\n",
      "               Date       Open       High        Low      Close   Volume\n",
      "0  2021-06-08 09-30  3221.7500  3221.7500  3221.7500  3221.7500  92230.0\n",
      "1  2021-06-08 09-31  3221.6001  3221.6001  3221.6001  3221.6001  24972.0\n",
      "2  2021-06-08 09-32  3219.3450  3219.3450  3219.3450  3219.3450  10677.0\n",
      "3  2021-06-08 09-33  3222.7200  3222.7200  3222.7200  3222.7200  15542.0\n",
      "4  2021-06-08 09-34  3223.6899  3223.6899  3223.6899  3223.6899   9926.0\n"
     ]
    }
   ],
   "source": [
    "for week_start in week_start_datetime:\n",
    "    for day_num in range(2):\n",
    "        trading_day = week_start + timedelta(days = day_num)\n",
    "        trading_day = trading_day.date()\n",
    "        cptv_trading_day_path = f'closing_price_trade_volume_data/AMZN_cptv_{trading_day}.xls'\n",
    "        cptv_trading_day_df = pd.read_excel(cptv_trading_day_path)\n",
    "        print(cptv_trading_day_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "supreme-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_week_to_min_max(week_start_datetime):\n",
    "    max_min_df = pd.DataFrame(columns=['date', 'max', 'max_time', 'min', 'min_time'])\n",
    "    i = 0\n",
    "    for week_start in week_start_datetime:\n",
    "        for day_num in range(5):\n",
    "            trading_day = week_start + timedelta(days = day_num)\n",
    "            trading_day = trading_day.date()\n",
    "            cptv_trading_day_path = f'closing_price_trade_volume_data/AMZN_cptv_{trading_day}.xls'\n",
    "            cptv_trading_day_df = pd.read_excel(cptv_trading_day_path)\n",
    "            cptv_trading_day_df.drop(cptv_trading_day_df.tail(1).index, inplace=True)\n",
    "            \n",
    "            max_min_df.loc[i] = trading_day, cptv_trading_day_df['Close'].max(), cptv_trading_day_df.loc[cptv_trading_day_df['Close'].idxmax()]['Date'], cptv_trading_day_df['Close'].min(),cptv_trading_day_df.loc[cptv_trading_day_df['Close'].idxmin()]['Date']\n",
    "            \n",
    "            i += 1\n",
    "    return max_min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "antique-delay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>max</th>\n",
       "      <th>max_time</th>\n",
       "      <th>min</th>\n",
       "      <th>min_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>3273.1101</td>\n",
       "      <td>2021-05-10 09-30</td>\n",
       "      <td>3192.9399</td>\n",
       "      <td>2021-05-10 15-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>3237.3516</td>\n",
       "      <td>2021-05-11 13-33</td>\n",
       "      <td>3144.6799</td>\n",
       "      <td>2021-05-11 09-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>3206.9900</td>\n",
       "      <td>2021-05-12 09-47</td>\n",
       "      <td>3134.8899</td>\n",
       "      <td>2021-05-12 14-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-13</td>\n",
       "      <td>3197.6499</td>\n",
       "      <td>2021-05-13 09-31</td>\n",
       "      <td>3133.8799</td>\n",
       "      <td>2021-05-13 13-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>3228.8145</td>\n",
       "      <td>2021-05-14 15-53</td>\n",
       "      <td>3188.6399</td>\n",
       "      <td>2021-05-14 09-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>3290.9951</td>\n",
       "      <td>2021-05-17 10-41</td>\n",
       "      <td>3235.0000</td>\n",
       "      <td>2021-05-17 13-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>3311.0000</td>\n",
       "      <td>2021-05-18 10-32</td>\n",
       "      <td>3244.8501</td>\n",
       "      <td>2021-05-18 14-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>3229.7549</td>\n",
       "      <td>2021-05-19 14-31</td>\n",
       "      <td>3188.0000</td>\n",
       "      <td>2021-05-19 09-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-05-20</td>\n",
       "      <td>3259.3899</td>\n",
       "      <td>2021-05-20 10-01</td>\n",
       "      <td>3236.3301</td>\n",
       "      <td>2021-05-20 12-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-05-21</td>\n",
       "      <td>3252.9099</td>\n",
       "      <td>2021-05-21 09-31</td>\n",
       "      <td>3197.5117</td>\n",
       "      <td>2021-05-21 15-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>3257.5500</td>\n",
       "      <td>2021-05-24 12-05</td>\n",
       "      <td>3211.8250</td>\n",
       "      <td>2021-05-24 09-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>3279.3999</td>\n",
       "      <td>2021-05-25 09-33</td>\n",
       "      <td>3216.6899</td>\n",
       "      <td>2021-05-25 11-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>3295.7300</td>\n",
       "      <td>2021-05-26 11-55</td>\n",
       "      <td>3258.6699</td>\n",
       "      <td>2021-05-26 15-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>3259.5100</td>\n",
       "      <td>2021-05-27 10-34</td>\n",
       "      <td>3234.6899</td>\n",
       "      <td>2021-05-27 15-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>3247.7700</td>\n",
       "      <td>2021-05-28 12-06</td>\n",
       "      <td>3220.2500</td>\n",
       "      <td>2021-05-28 15-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>3247.7700</td>\n",
       "      <td>2021-05-28 12-06</td>\n",
       "      <td>3220.2500</td>\n",
       "      <td>2021-05-28 15-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>3249.3101</td>\n",
       "      <td>2021-06-01 09-45</td>\n",
       "      <td>3210.7800</td>\n",
       "      <td>2021-06-01 10-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>3234.0000</td>\n",
       "      <td>2021-06-02 11-54</td>\n",
       "      <td>3209.1399</td>\n",
       "      <td>2021-06-02 14-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-06-03</td>\n",
       "      <td>3213.2500</td>\n",
       "      <td>2021-06-03 11-08</td>\n",
       "      <td>3184.8701</td>\n",
       "      <td>2021-06-03 15-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>3220.7000</td>\n",
       "      <td>2021-06-04 12-41</td>\n",
       "      <td>3199.3999</td>\n",
       "      <td>2021-06-04 15-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        max          max_time        min          min_time\n",
       "0   2021-05-10  3273.1101  2021-05-10 09-30  3192.9399  2021-05-10 15-53\n",
       "1   2021-05-11  3237.3516  2021-05-11 13-33  3144.6799  2021-05-11 09-34\n",
       "2   2021-05-12  3206.9900  2021-05-12 09-47  3134.8899  2021-05-12 14-19\n",
       "3   2021-05-13  3197.6499  2021-05-13 09-31  3133.8799  2021-05-13 13-38\n",
       "4   2021-05-14  3228.8145  2021-05-14 15-53  3188.6399  2021-05-14 09-31\n",
       "5   2021-05-17  3290.9951  2021-05-17 10-41  3235.0000  2021-05-17 13-42\n",
       "6   2021-05-18  3311.0000  2021-05-18 10-32  3244.8501  2021-05-18 14-46\n",
       "7   2021-05-19  3229.7549  2021-05-19 14-31  3188.0000  2021-05-19 09-38\n",
       "8   2021-05-20  3259.3899  2021-05-20 10-01  3236.3301  2021-05-20 12-38\n",
       "9   2021-05-21  3252.9099  2021-05-21 09-31  3197.5117  2021-05-21 15-50\n",
       "10  2021-05-24  3257.5500  2021-05-24 12-05  3211.8250  2021-05-24 09-31\n",
       "11  2021-05-25  3279.3999  2021-05-25 09-33  3216.6899  2021-05-25 11-39\n",
       "12  2021-05-26  3295.7300  2021-05-26 11-55  3258.6699  2021-05-26 15-40\n",
       "13  2021-05-27  3259.5100  2021-05-27 10-34  3234.6899  2021-05-27 15-53\n",
       "14  2021-05-28  3247.7700  2021-05-28 12-06  3220.2500  2021-05-28 15-48\n",
       "15  2021-05-31  3247.7700  2021-05-28 12-06  3220.2500  2021-05-28 15-48\n",
       "16  2021-06-01  3249.3101  2021-06-01 09-45  3210.7800  2021-06-01 10-57\n",
       "17  2021-06-02  3234.0000  2021-06-02 11-54  3209.1399  2021-06-02 14-14\n",
       "18  2021-06-03  3213.2500  2021-06-03 11-08  3184.8701  2021-06-03 15-55\n",
       "19  2021-06-04  3220.7000  2021-06-04 12-41  3199.3999  2021-06-04 15-16"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_df = convert_week_to_min_max(week_start_datetime)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "sporting-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_days = 6\n",
    "min_max_train_df = min_max_df.iloc[:-num_test_days, :]\n",
    "min_max_test_df = min_max_df.iloc[len(min_max_df)-num_test_days:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "independent-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "19\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(min_max_df))\n",
    "print(len(min_max_train_df))\n",
    "print(len(min_max_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "vital-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xy_split(df, col_name, test_size=5):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(df[col_name].values.reshape(-1, 1))\n",
    "    X = []\n",
    "    y = []\n",
    "    for day in range(test_size, len(scaled)):\n",
    "        X.append(scaled[day-test_size:day, 0])\n",
    "        y.append(scaled[day, 0])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "suitable-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_X_train, max_y_train = Xy_split(min_max_train_df, 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "artistic-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_X_test, max_y_test = Xy_split(min_max_test_df, 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "married-distributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 5, 1)\n",
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "print(max_X_train.shape)\n",
    "print(max_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-membership",
   "metadata": {},
   "source": [
    "# methods for decomposition for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "synthetic-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "common-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_start = '2021-05-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "military-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "cptv_week_csv = f'AMZN_cptv_{week_start}.csv'\n",
    "cptv_week_df = pd.read_csv(f'C:/Users/seant/stock_analyzer/weekly_data/{cptv_week_csv}', header=0, index_col=0)\n",
    "train = train.append(cptv_week_df, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_week_start = '2021-06-07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "impressed-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "cptv_week_csv = f'AMZN_cptv_{test_week_start}.csv'\n",
    "test = pd.read_csv(f'C:/Users/seant/stock_analyzer/weekly_data/{cptv_week_csv}', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "knowing-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "testday = pd.read_excel(f'C:/Users/seant/stock_analyzer/closing_price_trade_volume_data/AMZN_cptv_2021-06-14.xls', header=0, index_col=0)\n",
    "test = test.append(testday, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "civil-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = f'AMZN_cptv_train.csv'\n",
    "train.to_csv(path_or_buf=f'C:/Users/seant/stock_analyzer/weekly_data/{train_csv}')\n",
    "test_csv = f'AMZN_cptv_test.csv'\n",
    "test.to_csv(path_or_buf=f'C:/Users/seant/stock_analyzer/weekly_data/{test_csv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-flash",
   "metadata": {},
   "source": [
    "Massaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fewer-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(df, column_name_lst, minute_period=200):\n",
    "    rolled_df = pd.DataFrame()\n",
    "    for column_name in column_name_lst:\n",
    "        series = df.loc[:, column_name]\n",
    "        rolled_df[column_name] = series.rolling(minute_period, center=True).mean()\n",
    "    return rolled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "renewable-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(df, column_name_lst, minute_period=390):\n",
    "    df_copy = df.copy()\n",
    "    seasonal_resid_df = pd.DataFrame()\n",
    "    trend_df = pd.DataFrame()\n",
    "    for column_name in column_name_lst:\n",
    "        for_decompose = df_copy[[column_name]].dropna()\n",
    "        decomposed = seasonal_decompose(for_decompose, model='additive', period=minute_period)\n",
    "        trend_df[column_name] = decomposed.trend.dropna()\n",
    "        seasonal_resid_df[f'{column_name}_seasonal'] = decomposed.seasonal\n",
    "        seasonal_resid_df[f'{column_name}_resid'] = decomposed.resid\n",
    "    #add a column of constants?\n",
    "    return trend_df, seasonal_resid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(trend_df, minute_period=390, num_periods = 5):\n",
    "    num_prediction_periods = minute_period * num_periods\n",
    "    last_period_cut = trend_df.shape(0) - num_prediction_periods #want to use 5 periods of data to predict next period of close prices\n",
    "    X = trend_df.iloc[:, :Last_period_cut] #cuts last period off for features to predict from\n",
    "    y = trend_df.iloc[0, num_prediction_periods:] #cuts first column and period off for targets for prediction\n",
    "    #how to use 1 week of data to predict 1 day of prices? extrapolate trend out 1 period?\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "painful-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recompose(trend_df, seasonal_resid_df, column_name_lst, minute_period=390):\n",
    "    recomposed_df = pd.DataFrame(columns=column_name_lst)\n",
    "    for column_name in column_name_lst:\n",
    "        trend_list = []\n",
    "        for i in range(minute_periods / 2):\n",
    "            trend_list.append(0)\n",
    "        for value in trend_df[column_name].items():\n",
    "            trend_list.append(value)\n",
    "        for i in range(minute_periods / 2):\n",
    "            trend_list.append(0)\n",
    "        trend_series = pd.Series(trend_list)\n",
    "        recomposed_series = trend_series.add(seasonal_resid_df[f'{column_name}_seasonal'])\n",
    "        recomposed_series = recomposed_series.add(seasonal_resid_df[f'{column_name}_resid'])\n",
    "        recomposed_df[column_name] = recomposed_series\n",
    "    return recomposed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "freelance-performance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df = pd.Series(np.nan, index = range(0, int(390 / 2)))\n",
    "nan_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "altered-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_rolling_avg = 200\n",
    "\n",
    "train_rolled = pd.DataFrame()\n",
    "train_close_series = train.loc[:, 'Close']\n",
    "train_rolled = train_rolled.assign(rolling_close = train_close_series.rolling(minute_rolling_avg, center=True).mean())\n",
    "train_volume_series = train.loc[:, 'Volume']\n",
    "train_rolled = train_rolled.assign(rolling_volume = train_volume_series.rolling(minute_rolling_avg, center=True).mean())\n",
    "\n",
    "test_rolled = pd.DataFrame()\n",
    "test_close_series = test.loc[:, 'Close']\n",
    "test_rolled = test_rolled.assign(rolling_close = test_close_series.rolling(minute_rolling_avg, center=True).mean())\n",
    "test_volume_series = test.loc[:, 'Volume']\n",
    "test_rolled = test_rolled.assign(rolling_volume = test_volume_series.rolling(minute_rolling_avg, center=True).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "reliable-proposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Close      3197.335587\n",
       "Volume    11301.540000\n",
       "Name: 500, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rolled = roll(train, ['Close', 'Volume'])\n",
    "train_rolled.iloc[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "lucky-scratch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7729, 5)\n",
      "(1931, 3)\n"
     ]
    }
   ],
   "source": [
    "cptv_copy = cptv_week_df.copy()\n",
    "cptv_roll_close_for_decompose = cptv_copy[['rolling_close']].dropna()\n",
    "cptv_roll_vol_for_decompose = cptv_copy[['rolling_volume']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-optimum",
   "metadata": {},
   "source": [
    "X_train = combine all weeks into one dataframe, decompose into closing(trend_1 + trend_2), volume(trend), +1 column, add additional day as prediction happens to predict next day\n",
    "\n",
    "y_train = closing(trend_1 + trend_2)? target is next minute price? min, max of next day?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-resident",
   "metadata": {},
   "source": [
    "# neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "continent-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=10, return_sequences=True, input_shape=(max_X_train.shape[1], 1)))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(LSTM(units=10, return_sequences=True))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(LSTM(units=10, return_sequences=True))\n",
    "model.add(Dropout(rate=0.2))\n",
    "#model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='SGD', metrics=keras.metrics.MeanAbsolutePercentageError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "rubber-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 5, 1) (14,)\n"
     ]
    }
   ],
   "source": [
    "print(max_X_train.shape, max_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "removed-title",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3502 - mean_absolute_percentage_error: 100.7111\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3355 - mean_absolute_percentage_error: 97.3833\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3207 - mean_absolute_percentage_error: 94.3240\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3078 - mean_absolute_percentage_error: 91.1392\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2946 - mean_absolute_percentage_error: 88.0684\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2831 - mean_absolute_percentage_error: 85.1890\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2711 - mean_absolute_percentage_error: 82.2901\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2606 - mean_absolute_percentage_error: 79.4519\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2496 - mean_absolute_percentage_error: 76.8846\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2406 - mean_absolute_percentage_error: 74.3326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x170f1a734c0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(max_X_train, max_y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "pacific-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7687 - mean_absolute_percentage_error: 87.6703\n"
     ]
    }
   ],
   "source": [
    "results=model.evaluate(max_X_test, max_y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildNN(X, y, activation_function, metric, optimizer, hidden_layers=[7], batch_size=32, epochs=5):\n",
    "    skf = StratifiedKFold()\n",
    "    skf.get_n_splits(X, y)\n",
    "    sumofsquares = np.zeros([13])\n",
    "    sumofweights = np.zeros([13])\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=42)\n",
    "        model = keras.models.Sequential()\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        for i, layer in enumerate(hidden_layers):\n",
    "            if i == 0:\n",
    "                model.add(keras.layers.Dense(units=layer, input_dim=13, activation=activation_function))\n",
    "            else:\n",
    "                model.add(keras.layers.Dense(units=layer, activation=activation_function))\n",
    "        model.add(keras.layers.Dense(units=1, activation=activation_function))\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=keras.metrics.BinaryAccuracy()) #'sgd 'keras.metrics.BinaryAccuracy()\n",
    "        model.summary()\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "        print(\"Test Results:\")\n",
    "        results = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "        for i, layer_size in enumerate(hidden_layers):\n",
    "            for index in range(layer_size):\n",
    "                print(f\"hidden_layers[{i}] = index=[{index}] {model.weights[0].numpy()[:,index]}\")\n",
    "                sumofsquares += model.weights[0].numpy()[:,index]**2\n",
    "                sumofweights += model.weights[0].numpy()[:,index]\n",
    "                #print(f\"model.weights len = {len(model.weights)}\")\n",
    "    print(\"absvalues=\")\n",
    "    print(absvalues)\n",
    "    return sumofsquares,sumofweights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
